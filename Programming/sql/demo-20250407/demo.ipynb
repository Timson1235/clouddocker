{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install SQLAlchemy pymysql python-dotenv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connect to SQL Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It would be bad practice to store your database password into a Python script or Jupyter Notebook\n",
    "- Instead, we store the password in a separate `.env` file. \n",
    "- This is a text file that contains environment variables in the form of name=value pairs. \n",
    "- You can then load these variables into environment variables using the dotenv package.\n",
    "- Such a .env file should never be shared with others or checked into version control (will be covered in our lecture on git and Github)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv                        # Load passwords etc from .env file \n",
    "load_dotenv('.env')                                   # Absolute or relative path to the .env file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The package SQLAlchemy allows you to connect to different variants of SQL databases (e.g. MySQL, PostgreSQL, SQLite, ...).\n",
    "- To connect to a MySQL database, you need to specify both the database dialect (mysql) and choose an appropriate driver (pymysql or mysqlconnector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine                  # Connection to database\n",
    "import os                                             # Needed to access environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIALECT = 'mysql'\n",
    "DRIVER = 'pymysql'\n",
    "USER = os.getenv('MYSQL_USER')\n",
    "PASSWORD = os.getenv('MYSQL_PASSWORD')\n",
    "HOST = 'localhost'\n",
    "PORT = '3306'\n",
    "DB = 'music'\n",
    "\n",
    "connection_string = f\"{DIALECT}+{DRIVER}://{USER}:{PASSWORD}@{HOST}:{PORT}/{DB}\"\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Read from SQL Database to Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Inspecting the MySQL database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we inspect the available databases in our MySQL Server, and specifically the available tables in our \"music\" database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspector = inspect(engine)\n",
    "\n",
    "print('Available Databases:')\n",
    "inspector.get_schema_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspector.get_table_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Read full table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read entire tables into a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = pd.read_sql('charts', con=engine)\n",
    "tracks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 SQL Select Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can send arbitrary SQL queries to read data into a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"select * from charts limit 3\"\n",
    "pd.read_sql(query, con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"select * from charts where streams >  17000000\"\n",
    "pd.read_sql(query, con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"select count(*), avg(streams) from charts \"\n",
    "pd.read_sql(query, con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouped aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"select region, avg(streams) from charts group by region order by avg(streams) desc\"\n",
    "pd.read_sql(query, con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"select * from charts\n",
    "           left join tracks\n",
    "           on charts.track_id = tracks.id\"\"\"\n",
    "pd.read_sql(query, con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Write Pandas DataFrame to SQL Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this demo, we create some new DataFrame with aggregated data, and then write this data back to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"select region, avg(streams) as avg_streams from charts\n",
    "           left join tracks\n",
    "           on charts.track_id = tracks.id \n",
    "           group by region\n",
    "           order by avg_streams desc\"\"\"\n",
    "aggregated_data = pd.read_sql(query, con=engine)\n",
    "aggregated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data.to_sql(name=\"avg_streams_by_region\", \n",
    "                       con=engine, \n",
    "                       if_exists='replace',   # fail, replace, append \n",
    "                       index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect(engine).get_table_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Execute Arbitrary SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have only used Pandas `read_sql` and `write_sql` functions to interact with our database. **However, we can run arbitrary SQL from our Python session**. \n",
    "\n",
    "In the following we:\n",
    "\n",
    "1. Connect to our MySQL Server\n",
    "2. We create a new test database\n",
    "3. We create a new table from a Pandas DataFrame\n",
    "4. We clean up by dropping the table and the database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to MySQL Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do not connect to a specific database, but to the MySQL Server (one level higher in the hierarchy). This will allow us to manage (create, alter, delete ...)  entire databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = f\"{DIALECT}+{DRIVER}://{USER}:{PASSWORD}@{HOST}:{PORT}\"\n",
    "server_engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with server_engine.connect() as connection:\n",
    "    connection.execute(text('DROP DATABASE IF EXISTS test'))\n",
    "    connection.execute(text('CREATE DATABASE test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = f\"{DIALECT}+{DRIVER}://{USER}:{PASSWORD}@{HOST}:{PORT}/test\"\n",
    "test_engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = sns.load_dataset('titanic')\n",
    "titanic.to_sql(name='titanic', con=test_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up: drop table and database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with server_engine.connect() as connection:\n",
    "    connection.execute(text(\"Drop table if exists test.titanic\"))\n",
    "    connection.execute(text(\"Drop database if exists test\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close all open connections, if present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.dispose()\n",
    "server_engine.dispose()\n",
    "test_engine.dispose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "programming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
